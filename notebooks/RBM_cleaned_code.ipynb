{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid , save_image\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    used_data = pd.read_csv('../data/data.csv', index_col=0, parse_dates=True)\n",
    "    return used_data\n",
    "\n",
    "def get_all_tickers():\n",
    "    used_data = get_data()\n",
    "    return used_data.columns\n",
    "\n",
    "def get_returns():\n",
    "    used_data = get_data()\n",
    "    ret_day = ret_day = used_data.fillna(0)\n",
    "    S = np.exp(used_data.fillna(0)).cumprod()\n",
    "    ret_mon = S.resample('M').ffill().pct_change().dropna() # start 2000-02-29\n",
    "    return ret_day, ret_mon\n",
    "    \n",
    "def form_labels(tic):\n",
    "    # Prices and returns\n",
    "\n",
    "    ret_day, ret_mon = get_returns()\n",
    "    median_ret = ret_mon.median(1)\n",
    "    labels = ret_mon.shift(-1).gt(median_ret.shift(-1), axis=0).astype(int)[tic]\n",
    "    labels.name = 'label'\n",
    "    return labels\n",
    "    #next_isjan = (ret_mon.shift(-1).index.month == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_features(tic):\n",
    "    ret_day, ret_mon = get_returns()\n",
    "    \n",
    "    feature_data = []\n",
    "        \n",
    "    daily = ret_day[tic]\n",
    "    dfs = []\n",
    "    idx = range(13, len(ret_mon) - 1)\n",
    "    for t in idx:\n",
    "        current_y = ret_mon.index[t].year\n",
    "        current_mon = ret_mon.index[t].month\n",
    "        next_mon_isjan = (ret_mon.index[t+1].month == 1)\n",
    "\n",
    "        start = t - 13\n",
    "        end = t - 2\n",
    "\n",
    "        ret_mon_slice = ret_mon[tic].iloc[start:end+1]\n",
    "\n",
    "        last_date = (daily[(daily.index.year == current_y) \n",
    "                           & (daily.index.month == current_mon)].last_valid_index())\n",
    "\n",
    "        last_date_loc = daily.index.get_loc(last_date)\n",
    "        start_date_loc = last_date_loc - 19\n",
    "\n",
    "        daily_rets_slice = daily.iloc[start_date_loc:last_date_loc + 1]\n",
    "\n",
    "        daily_rets_slice.index = ['R_d_' + str(i) for i in range(1, 21)]\n",
    "        ret_mon_slice.index = ['R_m_' + str(i) for i in range(1, 13)]\n",
    "\n",
    "        conc = pd.concat([daily_rets_slice, ret_mon_slice])\n",
    "        conc['JAN'] = next_mon_isjan\n",
    "\n",
    "        conc = conc.to_frame()\n",
    "        conc.columns = [t]\n",
    "        dfs.append(conc)\n",
    "    feats_t = pd.concat(dfs, axis=1).T\n",
    "    feature_data.append(feats_t)\n",
    "    \n",
    "    date_idx = ret_mon.index[idx]\n",
    "    feature_data_df = pd.concat(feature_data, axis=0).set_index(date_idx)\n",
    "    return feature_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def form_feats_labels(tickers):\n",
    "    full_data_by_tic = []\n",
    "    for tic in tickers:\n",
    "        feats = form_features(tic)\n",
    "        labels = form_labels(tic)\n",
    "        conc = pd.concat([feats, labels], axis=1, join='inner')\n",
    "        full_data_by_tic.append(conc)\n",
    "    return pd.concat(full_data_by_tic, axis=0) # datetime index not unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_importer(train_set_size=0.3):\n",
    "    tickers = get_all_tickers()\n",
    "    data = form_feats_labels(tickers)\n",
    "    X = data[data.columns[:-1]].as_matrix()\n",
    "    y = data.label.as_matrix()\n",
    "    \n",
    "    N = len(y)\n",
    "    train_set_stop = int(N * train_set_size)\n",
    "    \n",
    "    return X[0:train_set_stop], y[0: train_set_stop], X[train_set_stop:], y[train_set_stop:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FutureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(33, 50)\n",
    "        self.fc21 = nn.Linear(50, 4)\n",
    "        self.fc22 = nn.Linear(50, 4)\n",
    "        self.fc3 = nn.Linear(4, 50)\n",
    "        self.fc4 = nn.Linear(50, 33)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = Variable(torch.rand(std.size()), requires_grad=False)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 33))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "        \n",
    "    def loss_function(self, recon_x, x, mu, logvar):\n",
    "        MSE = F.mse_loss(recon_x, x.view(-1, 33), size_average=False)\n",
    "\n",
    "        # see Appendix B from VAE paper:\n",
    "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "        # https://arxiv.org/abs/1312.6114\n",
    "        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        return MSE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train and test data\n",
    "Xtrain, ytrain, Xtest, ytest = data_importer()\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = FutureDataset(Xtrain, ytrain)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = FutureDataset(Xtest, ytest)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_interval = 100\n",
    "number_of_epochs = 500\n",
    "\n",
    "vae = VAE()\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:10: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 99 Average loss: 0.0706\n",
      "====> Epoch: 199 Average loss: 0.0619\n",
      "====> Epoch: 299 Average loss: 0.0595\n",
      "====> Epoch: 399 Average loss: 0.0582\n",
      "====> Epoch: 499 Average loss: 0.0553\n"
     ]
    }
   ],
   "source": [
    "vae.train()\n",
    "for epoch in range(number_of_epochs):\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data.float())\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = vae(data)\n",
    "        loss = vae.loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % log_interval == 0:\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:6: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "vae.eval()\n",
    "test_loss = 0\n",
    "for i, (data, _) in enumerate(test_loader):\n",
    "    data = Variable(data.float(), requires_grad=False)\n",
    "    recon_batch, mu, logvar = vae(data)\n",
    "    test_loss += vae.loss_function(recon_batch, data, mu, logvar).data[0]\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build encoded dataset\n",
    "Xenc = np.array([]).reshape(0, 4)\n",
    "yenc = np.array([])\n",
    "for _, (data,target) in enumerate(train_loader):\n",
    "    data = Variable(data.view(-1,33)).float()\n",
    "    labels = Variable(target).type(torch.LongTensor)\n",
    "    \n",
    "    _, data, _ = vae(data)\n",
    "    \n",
    "    batch = data.cpu().data.numpy()\n",
    "    Xenc = np.vstack((Xenc, batch))\n",
    "    yenc = np.append(yenc, target.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.521452145215\n",
      "What features are prefered [ 0.25883305  0.23334922  0.16755382  0.34026391]\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST CLASSIFIER\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(Xenc, yenc)\n",
    "score = cross_val_score(clf, Xenc, yenc)\n",
    "print(score.mean())\n",
    "\n",
    "print(\"What features are prefered\", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.544554455446\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYESIAN CLASSIFIER\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(Xenc, yenc)\n",
    "score = cross_val_score(gnb, Xenc, yenc)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ORGINAL DATA\n",
    "tickers = get_all_tickers()\n",
    "X_and_y = form_feats_labels(tickers)\n",
    "Xorg = X_and_y[X_and_y.columns[:-1]].as_matrix()\n",
    "yorg = X_and_y.label.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.566607797383\n",
      "What features are prefered: \n",
      " [ 0.05484949  0.01222888  0.03551346  0.02605386  0.02988995  0.03855984\n",
      "  0.03229935  0.04909894  0.03012636  0.02125024  0.03333895  0.05573694\n",
      "  0.02418763  0.02396154  0.02687858  0.02175336  0.02706231  0.01459803\n",
      "  0.02792436  0.02921282  0.04249237  0.03042023  0.02398243  0.04552304\n",
      "  0.02927211  0.03401704  0.03055389  0.04590096  0.02598591  0.01867101\n",
      "  0.03010383  0.02758927  0.000963  ]\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST CLASSIFIER ONLY\n",
    "clf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "score = cross_val_score(clf, Xtest, ytest)\n",
    "print(score.mean())\n",
    "\n",
    "print(\"What features are prefered: \\n\", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.528877887789\n"
     ]
    }
   ],
   "source": [
    "# ADABOOST ONLY\n",
    "ada = AdaBoostClassifier(n_estimators=10)\n",
    "ada.fit(Xorg, yorg)  \n",
    "score = cross_val_score(ada, Xorg, yorg)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509075907591\n"
     ]
    }
   ],
   "source": [
    "# SVC ONLY\n",
    "svc = SVC(gamma=2, C=1)\n",
    "svc.fit(Xorg, yorg)\n",
    "score = cross_val_score(svc, Xorg, yorg)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BROKEN, PREDICTION RESULTS FROM ENCODER PIPELINE\n",
    "prediction_outputs = []\n",
    "returns = []\n",
    "\n",
    "classifier = clf\n",
    "\n",
    "for idx, observation in enumerate(Xorg):\n",
    "    data = torch.from_numpy(observation)\n",
    "\n",
    "    data = Variable(data).float()\n",
    "    _, data, _ = vae(data)\n",
    "    output = classifier.predict_proba(data.cpu().data.numpy())\n",
    "    prediction_outputs.append(output[0])\n",
    "\n",
    "len(prediction_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_positions(prediction_outputs):\n",
    "    result_df = pd.DataFrame(prediction_outputs, columns=[\"loser_p\", \"winner_p\"])\n",
    "    label = (result_df[\"winner_p\"] > result_df[\"loser_p\"]).astype(int) # <\n",
    "    result_df[\"longshort\"] = label.map({1: 1, 0: -1})\n",
    "\n",
    "    print(\"Predicted long count:\", sum(label))\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted long count: 115\n",
      "Predicted long count: 84\n",
      "Predicted long count: 81\n",
      "Predicted long count: 90\n",
      "Predicted long count: 181\n",
      "Predicted long count: 188\n"
     ]
    }
   ],
   "source": [
    "result_dfs = {}\n",
    "\n",
    "for tic in [\"ES\", \"FESX\", \"GC\", \"NK\", \"TU\", \"ED\"]:\n",
    "    X = form_features(tic)\n",
    "    prediction_outputs = clf.predict_proba(X)\n",
    "    df = get_positions(prediction_outputs).set_index(X.index)\n",
    "    result_dfs[tic] = df[['longshort']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "ret_day, ret_mon = get_returns()\n",
    "ret_mon_slice = ret_mon.iloc[13:]\n",
    "for key in result_dfs.keys():\n",
    "    newcol = str(key) + '_pos'\n",
    "    ret_mon_slice[newcol] = result_dfs[key]\n",
    "ret_mon_slice = ret_mon_slice.resample('M').ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe 1.98058711982\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4FXX+/v/nKxVIQk0IvUqXJgFEVFwVFde+itg76rrd\nz2/dZttdd9XVteGqrAWxoO7i2rvSFOkCUkNLCARISEJJAgnJeX//OAd+AQkJZJI5Obkf15WL5Myc\nmTsnk5vJnPfMmHMOERGJLFF+BxAREe+p3EVEIpDKXUQkAqncRUQikMpdRCQCqdxFRCKQyl18Y2b3\nmdmrdb0uM+tkZoVmFl0X6z5WZnaKma32O4fUTyp3aXCccxudc4nOufKaLMfMppvZzV7lOpRzbpZz\nrldtLV8im8pdJAyZWYzfGaR+U7lLjZnZXWb230Mee8LMnjSzdmb2npnlm9laM7vlCMv5j5ltNbOd\nZjbTzPodYd4WZvaBmeWaWUHo8w4Vpnc1sxlmttvMPgeSK0zrYmZuf4GaWYaZnVlhesVDOI3M7FUz\nyzOzHWY238xSzewB4BRgQugQz4TQ/L3N7PPQ97vazMZWWG68mT1iZhvNbJuZPWtmjUPTTjOzTaHX\ncivw0v7HKjw/w8z+z8yWhl6jN82sUYXpvzWzLWaWbWY3h77H4470s5PIpXIXL7wBnGtmSQChY9lj\ngddD0zYB7YBLgb+Z2emVLOdjoAfQGlgEvHaEdUYBLwGdgU7AHmBChemvAwsJlvpfgOuO5RsLPa8Z\n0BFoBdwG7HHO/RGYBfwsdIjnZ2aWAHweWndrYBzwLzPrG1rWg0BPYBBwHNAeuKfCutoALUPf0/hK\n8owFzgG6AgOA6wHM7BzgN8CZoWWfdozfr0QIlbvUmHMuk2AZXxx66HSgGNgMjATucs7tdc4tBp4H\nrq1kOS8653Y750qA+4CBZtasknnznHNTnXPFzrndwAPAKAi+YQoMBe52zpU452YC7x/jt7ePYKkf\n55wrd84tdM7tqmTe84AM59xLzrky59x3wFTgMjMzgoX9a+dcfijz3wj+B7BfALg3lHlPJet40jmX\n7ZzLD31Pg0KPjwVecs4td84VE3z9pAFTuYtXXgeuCH1+ZejrdsD+Itsvk+Ae60HMLNrMHjSzdWa2\nC8gITUquMLql0MwKQ/M3MbPnzCwzNP9MoHnor4Z2QIFzruiQ9R6LV4BPgTdChzseNrPYSubtDAwP\nHb7ZYWY7gKsI7pGnAE2AhRWmfRJ6fL9c59zeKvJsrfB5MZAY+rwdkFVhWsXPpQFSuYtX/gOcFjru\nfTHBcs8GWu4/XBPSieAe/aGuBC4keFihGdAl9LhVGN2S6JzbX2Z3Ar2A4c65psCp++cHtgAtQodJ\nKq63MkUEi3e/Nvs/cc7tc87d75zrC5xEcO98/18eh15SNQuY4ZxrXuEj0Tl3O7Cd4KGjfhWmNavw\n/RxueUdjC9Chwtcda7AsiQAqd/GEcy4XmE7wOPgG59xK51wWMBv4e+iNyQHATcDhxrYnASVAHsGi\n/VsVq0wiWJY7zKwlcG+FLJnAAuB+M4szs5OB84+wrMXAODOLNbM0gu8NAGBmPzKz/qG/CHYRPEwT\nCE3eBnSrsJwPgJ5mdk1oWbFmNtTM+jjnAsC/gcfMrHVo2e3N7Owqvs/qegu4wcz6mFkT4G6Pliv1\nlMpdvPQ6wT3v1ys8dgXBvfBs4H8Ejyl/cZjnTiZ46GQzsAKYU8W6HgcaE9wjnkPwEEdFVwLDgXyC\nxT/5CMu6G+gOFAD3H5K/DfBfgsW+EphB8FANwBPApaHROk+GDj+dRfA4ejbBQygPAfGh+e8C1gJz\nQoeSviD410eNOec+Bp4Epu1fR2hSiRfLl/rHdLMOaWjMrBuQDsS6CP0FMLM+wDIg3jlX5nceqXva\nc5eG6HggM9KK3cwuDo2lb0HwL4b3VewNV5XlbmYdzWyama0ws+Vm9svDzGMWPGFlbegEixNqJ65I\nzZjZb4CJwO/8zlILbgVygHVAOXC7v3HET1UeljGztkBb59yi0KiHhcBFzrkVFeY5F/g5cC7B45xP\nOOeG115sERE5kir33J1zW5xzi0Kf7yb4ptKh45QvBCa7oDkExxu39TytiIhUy1FdnMjMugCDgbmH\nTGrPwSdNbAo9tuWQ548ndFp1QkLCkN69ex9dWhGRBm7hwoXbnXMpVc1X7XI3s0SCp1L/6ginXx+R\nc24iweOdpKWluQULFhzLYkREGiwzq9bZ1tUaLRM63Xoq8Jpz7u3DzLKZg8+I68Dhz0IUEZE6UJ3R\nMga8AKx0zv2zktneA64NjZo5EdjpnNtSybwiIlLLqnNYZiRwDfC9mS0OPfYHQtfqcM49C3xEcKTM\nWoIXM7rB+6giIlJdVZa7c+5rghdjOtI8DrjDq1AiIlIzOkNVRCQCqdxFRCKQyl1EJALpDusiIrVk\nY14x7y3ZTFKjWJo3iaVv26b0SE2q+okeULmLiNSSu99dxoz03ANfx0QZn/zqFI5rXfsFr8MyIiIe\n2lFcysLMApZt3smM9FzuHN2TBX86kw9+fjKNYqN56JPVdZJDe+4iIh4pDzhumbyA+RkFJCfGkxQf\nw3Uju9C0USzJifHcflp3/vHpauZtyGdY15a1mkV77iIiHnnh6/XMzyjg7H6pFBSXcuPJXWnaKPbA\n9BtHdiW1aTzTVufUehbtuYuI1EBJWTkLMgp4Y34WHy7N5qy+qTx79RB2FO+jWePYg+ZtHBfNx788\nlZYJcbWeS+UuInKMNu/Yw0VPf0Pu7hIS42O45ZRu3HH6cZgZLSop8LoodlC5i4gctbLyANFRxu+m\nLqWopIznrhnCKT2SaRIXPpUaPklEROqBrPxiznl8Jo3jYtheWMKfL+zH2f3a+B3rB1TuIiJH4ZkZ\n69hX7hjVtQVJ8bFcPbyz35EOS+UuIlJNW3bu4b8LNnFZWgceuLi/33GOSEMhRUSq6ZFP0wk4x22j\nuvsdpUoqdxGRanh97kamLtrEbaO607FlE7/jVEmHZUREjuC5GeuY/G0mm3fsYVTPFH49uqffkapF\n5S4iUolnpq/joU9WMfK4VlwzojNXDe9EdNQRb0wXNlTuIiKH8fLsDB76ZBUXDGzHY5cPqjelvp/K\nXUSkgtKyAC9+s4EHP17F6L6pPDp2YL0rdlC5i0gDUlxadtBZpJO/zWD22jw6tGjMmX1T2bZrL49+\nls7G/GJG901lwpWDiY2un+NOVO4i0iBM+GoN//w8nTvP6sVPT+vOa3M3cs+7y2nbrBHTVufw/Ncb\nAOjTtimTbhjKqJ4pmNW/Pfb9VO4iErGy8ov50zvL2FceYPa6PDq2bMw/Pl3NpNkZ5O4u4fTerZl4\nzRBKywN8sTKHuGjjrL5tiKqHh2EOpXIXkYj17uLNzEjPpWdqIjed3JXfj+nNS99ksGLLLrqnJHDD\nyK7EREcREx3FBQPb+R3XUyp3EYlYM9O3c3z7pnzw81MOPHbLqd18TFR36uc7BSIiVdi9dx+LNhZw\nao8Uv6P4QuUuIhHp23V5lAUcp/ZUuYuI1Dt7SssJBNwPHp+5JpeEuGhO6NTCh1T+U7mLSL21e+8+\nzvznDG59dSHOBQt+T2k5D32yijfmZXFqzxTiYhpmzekNVRGptx7/Yg2bd+xh8449vLUgi2aNY3ng\no5Vk5e/h0iEd+OO5ffyO6BuVu4jUS6u27mLS7AzGDe3I2pxC7pr6PQDdkhOYcsuJjOjeyueE/lK5\ni0i945zjnneW07RRDHed05vCkjJe+HoDp/RI5tSeKfX2kgFe0isgImFn1ppcxk9ewL7ywGGn/++7\nzczLyOeuc3rTIiGOji2bcN8F/TijT6qKPaTKV8HMXjSzHDNbVsn0Zmb2vpktMbPlZnaD9zFFpCF5\nc34Wn63Yxlercn4wbduuvTzw4UoGdWzO2LSOPqSrH6rzX9wk4JwjTL8DWOGcGwicBjxqZnE1jyYi\nDZFzjjnr8wGYMm8j01fnMH7yAmak51JQVMov3/iO4tJyHrlsQERcA6a2VHnM3Tk308y6HGkWIMmC\nl09LBPKBMk/SiUiDsy63iO2FJXRu1YQZ6bnMXZ9PSVk5n63YdmCeRy8byHGtk3xMGf68eEN1AvAe\nkA0kAZc75w57oMzMxgPjATp16uTBqkUk0sxZnwfA3y/uz1UvzKVVYhxv3jqCeRvyKCjaR9eUBH7U\nq7XPKcOfF+V+NrAYOB3oDnxuZrOcc7sOndE5NxGYCJCWlvbDU8pEpMGatSaXN+ZnkVdYQpumjRjR\nvRWv3TycrskJtG3WmIsHd/A7Yr3iRbnfADzogqeHrTWzDUBvYJ4HyxaRBsA5xwMfrmTV1t0AXDSo\nHWbGSd2TfU5Wf3lR7huBM4BZZpYK9ALWe7BcEWkgvlmbx6qtu/ntOb3I3V3CJdpLr7Eqy93MphAc\nBZNsZpuAe4FYAOfcs8BfgElm9j1gwF3Oue21llhEIs7zX68nOTGem07uSnxMtN9xIkJ1RstcUcX0\nbOAszxKJSIOSX1TK9NW5/OL041TsHtKpXCLiq0WZBQCc3EBvqlFbVO4i4qsFmQXERhsDOjTzO0pE\nUbmLSK37ZNkW7nl3GTv37PvBtEWZBfRr14xGsTok4yWVu4h4akdxKXe8vohv1gbHVWTmFfGbt5Yw\n+dtMfvzkLNblFh6Yt7QswJJNO0jr3DDvllSbVO4i4qmHP13Nh0u3cMNL83niizX8fMp3REcZz1x1\nAoUlZfzh7e9xzpGVX8zcDXmUlAUYonL3nK7nLiKeWZK1gynzNjJuaEfSt+3msS/SiYuJ4tHLBjKm\nf1vyikr50zvLGP/KQj6vcK0Ylbv3VO4i4plHPltNcmI8f/xxHxLiYsgrKqVFk1hiQtdYv2JYJ16b\nu5HPV2zj4sHtadEkDjNo3bSRz8kjj8pdRDyRsb2IWWu2c+foniQ1igUgJSn+oHmio4znrh7Cii07\nObtfG4IXk5XaoHIXEU9Mmb+R6Chj7NAj30CjU6smdGrVpI5SNVwqdxGpkfeXZPPJ8q18vWY7o/uk\nkqpDLGFB5S4ix6ysPMBfPljBntJy4mKiuPmUrn5HkhCVu4gcs5lrcsnZXcJz1wzh7H5t/I4jFWic\nu4gcszfnZ5GcGMfpvXVnpHCjcheRY5Kzay9frszhkhM6EButKgk3+omIyDF57It0AK4cpvshhyOV\nu4gcteXZO3ljfhbXndSFLskJfseRw1C5i8hRe/yLNTRvHMsvTu/hdxSphMpdRI5KcWkZM9NzuWhw\ne5o1ifU7jlRC5S4iR+XrNdspKQtwZp9Uv6PIEajcReSofLkyh6RGMQzr2tLvKHIEKncRqbZAwPHl\nqhxG9UzR8Mcwp5+OiPzA7r37eGVOJnv3lR/0+KTZGWwvLGF0Xx2SCXe6/ICI/MCjn6UzaXYGeYUl\n/OrMnjjneHraWh75LJ0z+6Qy5vi2fkeUKqjcReQg63ILeXVOJo1io3huxnpO69Waf89az4dLt3Dh\noHY8ctlAHZKpB/QTEpEDFmft4FdvLKZRbDSv3XwiZYEAFz39DR9/v4XfjenN45cPUrHXE9pzFxEA\n3l28mV++sZiWCXE89JMBDOncgr9d3J+s/GIuS+tIx5a6wUZ9onIXEbLyi/nT/5aR1rkFk24cRmJ8\nsBouSzvyXZUkfOnvK5EGbt6GfG6cNB8HPHb5oAPFLvWbyl2kAXtj3kbGPvcthSVlPH3VCTr0EkH0\nX7RIA7Vs807ueW85p/RIZuI1aTSOi/Y7knhIe+4iDdCyzTu5+eUFtGwSx+OXD1KxRyDtuYtEMOcc\nd/5nCU0bxfLr0T3JKyzh7UWbeeHrDbRoEssL1w+lVWK83zGlFqjcRSLYoo0FvL1oMwAvf5uBcxBl\nMLpvKn+56HhaJzXyN6DUmirL3cxeBM4Dcpxzx1cyz2nA40AssN05N8rLkCJybF6ds5HE+BgmXjuE\n6atz6ZacwMk9kunQQm+cRrrq7LlPAiYAkw830cyaA/8CznHObTQz3QZdJAzkF5Xy4dItjBvWkZO6\nJ3NS92S/I0kdqvINVefcTCD/CLNcCbztnNsYmj/Ho2wiUgNvLciitDzA1Sd29juK+MCL0TI9gRZm\nNt3MFprZtZXNaGbjzWyBmS3Izc31YNUicjiBgOO1uZkM69qSnqlJfscRH3hR7jHAEODHwNnA3WbW\n83AzOucmOufSnHNpKSkpHqxaRA5nxppcsvL3cI322hssL0bLbALynHNFQJGZzQQGAukeLFtEjsGr\n32aSnBjP2f3a+B1FfOLFnvu7wMlmFmNmTYDhwEoPlisix+Cz5Vv5clUOV5/YibgYnafYUFVnKOQU\n4DQg2cw2AfcSHPKIc+5Z59xKM/sEWAoEgOedc8tqL7KIVGbrzr38dupS+rVryu2ndfc7jvioynJ3\nzl1RjXn+AfzDk0QiUi0lZeVc+e+5XD60I2NDl+Z9+NNV7Ckt58krBhMfo0sKNGQ6Q1Wknvrfos0s\nzCxgbU4ho/ukUlBcyjvfbebGkV3pnpLodzzxmcpdJIxN/jaDz1ds49oRXfhgaTZLsnZwVr82XDGs\nExNnrqdTyyZsKijm3veWs3vvPuJiorh1lA7HiMpdJGx99P0W7nl3OXHRUcxas524mCiGdmnBi19v\nYOLM9QA8dcVg5m3I55U5mQD86swepCTpQmCichcJS99tLODXby5mSOcWvHBdGjPXbGdA+2Z0SU4g\nZ9denpu5nq079zLm+Dac1S+VsWkdaZEQq2vGyAHmnPNlxWlpaW7BggW+rFsknGXlF3Pxv76hSVwM\n//vpSbokrxzEzBY659Kqmk977iJhZOmmHdz88gJKywK8MV7XWpdjp3IXCQP5RaU89dUaXpuzkZSk\neCbfNIzjWmvEixw7lbuIzzLzirj6hblk79jLT05oz13n9NYeu9SYyl3ERxu2F3H5c99SWh7gv7eN\nYHCnFn5Hkgihchfxwd595azZVshtry6kLOB469YRujSveErlLlLHpq/O4Y7XFlFUWk5SfAxTxp+o\nYhfPqdxFalkgEBxuHBVlTFuVw62vLuS4lERuHdWNtC4tad+8sc8JJRKp3EVqUVl5gOtemsfqrYWM\nPK4V7y3Jpm/bprx603BaJMT5HU8imC72LFKL/vHpar5Zm0f7Fo15d3E2l57Qgf/cNkLFLrVOe+4i\nteSFrzfw3Mz1XH1iJ/56UX9Kysp1GV6pMyp3kVrw9LS1/OPT1ZzdL5W7z+sLoGKXOqVyF/HYwsx8\nHvlsNRcMbMdjlw8iOsr8jiQNkI65i3iosKSMO99aQvvmjfnbJf1V7OIb7bmLeKSwpIzrX5xHVsEe\nXr1pOInx+vUS/2jPXcQDzjnueG0Ri7N28NQVgxnRvZXfkaSBU7mLeOCrVTnMSM/l9+f24dz+bf2O\nI6JyF6mpfeUB/vbRSrqlJHDtiM5+xxEBVO4iNfa3j1ayLreIP57bh9ho/UpJeNCWKFIDL8/O4KVv\nMrjp5K6c0SfV7zgiB6jcRY7RV6u2cf/7yxndN5U/nNvH7zgiB9FYLZGjVFBUyn8XbuLxL9Lp164Z\nT4zTiUoSflTuIkchfdturnp+Lrm7SxjWtSVPXTGYJnH6NZLwo61SpJoyQrfEi42O4r2fjWRAh+Z+\nRxKplMpdpJomzc6gqKScz38zks6tEvyOI3JEekNV5Aj2lQf4Zu12SsrKeW9JNqP7pqrYpV7QnrvI\nEbw8O4O/friSEd1akV9UyqVDOvgdSaRatOcucgSfLt9KlMG36/NISYrnlB7JfkcSqRbtuYtUIq+w\nhIWZBdx+Wnfyi/YxqGMzYnQGqtQTVZa7mb0InAfkOOeOP8J8Q4FvgXHOuf96F1Gk7ny6fCutEuJI\n69KSL1flEHAw5vi2HN++md/RRI5KdfbcJwETgMmVzWBm0cBDwGfexBKpXXv3lbOjeB9m0KxxLLv3\nlvH0tLVMmp0BwMCOzdm1Zx/tmzemX7um/oYVOQZVlrtzbqaZdalitp8DU4GhHmQSqVXfb9rJtS/O\npaB43w+m3TiyKx1bNuad7zaTX1TKzSd3xUxnn0r9U+Nj7mbWHrgY+BFVlLuZjQfGA3Tq1KmmqxY5\nass27+Sq5+eQ1CiW/zu7F87Bzj37SIyPoXebJIZ3C95k44aRXX1OKlIzXryh+jhwl3MuUNUejnNu\nIjARIC0tzXmwbpHDmrM+j3kb8rl2RGeaN4kDYMvOPdw4aT5JjWJ589YT6dCiic8pRWqPF+WeBrwR\nKvZk4FwzK3POvePBskWO2kvfbOCvH66kPOD496z1tEqIo7CknLJAgLJyx9Tbh6vYJeLVuNydcwf+\nfjWzScAHKnbxy/yMfO5/fwWj+6Zy26juvPJtBmUBR1KjGApLyrl6eCd6tUnyO6ZIravOUMgpwGlA\nspltAu4FYgGcc8/WajqRoxAIOP76wQraNG3Ek+MG0zgumiGdW/gdS8QX1Rktc0V1F+acu75GaURq\n4L0l2SzZtJNHLhtI47hov+OI+Eqn20m9sCRrB9NX51Q6PWf3Xu5/fzkDOzTjksHt6zCZSHjS5Qck\nrAUCjie+XMNTX60h4ODO0T05vkMzZqbnMm1VDilJ8fRu05QVW3ZRXFrOo2MHEqW7Iomo3CW8/fPz\ndCZMW8slJ7SnPOB49PN0AOKiozi5RzI7ikt5b0k2e0rLufeCvhzXWm+WioDKXcLYu4s3M2HaWsYN\n7cjfL+mPc3DhoHYkxMXQt11TkhrFHpi3POB0H1ORClTuElYCAYcZbCrYwx/e/p5hXVry5wuPx8ww\ng9N7px72eSp2kYOp3CWs/PLNxXy7Lo+WCcG98kfHDiQuRu/7ixwt/daIb4pLy3jl2wx27glewCsz\nr4gPlmYTHxNF+rZC7j2/Hx1b6kxSkWOhPXfxzd3vLGfqok28MieTF68fysuzM4k24+2fnkSjmGia\nNYmteiEiclgqd/HFu4s3M3XRJs4b0JYZq3M5/dEZGHBu/7akNm3kdzyRek/lLnWuqKSMP7+/gsGd\nmvP45YPYvGMP/561numrc7l1VDe/44lEBJW71LkXv95AXlEpz1+XRkx0FJ1bJfDXi/r7HUskougN\nValTObv2MnHmekb3TWVwJ13US6S2qNyl1pSVBw76evXW3VzyzGz2BQL8f2f38imVSMOgwzLCK3My\n+XBpNpNuGEajWG+upvjVqm3c9PICUhLj6Z6SSHxsFDPTc2mZEM9bt46gZ6ouEyBSm7Tn3sBlbC/i\nLx+sYM76fF6dk+nZcp+eto42TRtxas8U9paVsz63iNtGdeejX57MgA7NPVuPiBye9twbMOccd7+7\njLjoKI5v15QJ09bSOjQM8bz+bY/56oqLNhawMLOA+87vy/W60bSIL1TuDciK7F0s3FjAxYPbkxgf\nw1ercpi1Zjv3nt+XoV1act5TX/OLKd8BMHXhJh67fBAtE+Kqvfxpq3L4w/++pzzgaNoohsvSOtbW\ntyIiVVC5NxB795Vz26sL2ZhfzD8+WcVdY3rz8uwMurRqwtUndiY2Ooq3bh1BXEwUyzbv5M8frODK\nf8/h9VtOrFbB7ygu5bdTlxIfE0WHFo25YGA7EuK1eYn4Rb99DcRzM9azMb+Y+y/ox6fLt/LH/y0D\n4OkrTyA2OvjWy7CuLQEY1LE5XZMTuHHSfM785wxiooyTurfizrN6HbjWS2lZgLcXbWJdbiGFJeWs\nyN5JQVEp7/5sJP3aNfPnmxSRA1TuEaykrJwnvljDe0uy2bxjDz8e0JbrTurCNSd25oWvN5CRV8S5\n/dsc9rkjj0tm0g3DeHVuJjFRxsfLtvLp8m1MvmkYZeWO3729lMy8YhrHRpMQH0NCfDT3XdBPxS4S\nJsw558uK09LS3IIFC3xZd0OwMDOfP72znJVbdnFmn9b0b9+c60/qcswX49q8Yw/XPD+Xrbv2sndf\nOV1aJXDP+X0Z1TMFM11LXaSumNlC51xaVfNpzz0CTfhqDY98lk5q03ievzaNM/se/gYXR6N988a8\nevNwrnlhLn3aNuXBnwwgUcfURcKWfjsjTMb2Ip74cg1jjm/Do2MH0iTOux9xu+aN+eI3o7SnLlIP\n6CSmCLJ77z4e+GglsdFR3H9BP0+LfT8Vu0j9oD33CHH3O8t4JXSG6W9G9zxwMpKINEwq9zDw+Ypt\nvDY3k3+OPbqThvabvXY7r8zJ5KJB7Ti3f1vO7FPzY+wiUr+p3H324tcb+MuHK3AOXp+byc9O7/GD\neZZn72TNtkKio4z3l2TTvkVj7jmvL2tzCpm1JljsnVo24cGfDPDswl8iUr+p3H3inOPJL9fy2Bfp\nnN0vlZ179vHa3I3cNqo7MaGTipxzvDZ3I/e9t5yyQHDIamJ8DIUlZZSUBXj3u80UlZbTODaaidcO\nUbGLyAEq9zoWCDg+Wb6Vf89az3cbd/CTEzrw8KUD+GpVDrdMXsDb323mjN6teWdxNm/O30j6tkJ+\n1CuFu8b0pri0nOPbNeOO1xfx+tyNdEtJ4KXrh9K+eeMD/yGIiIBOYqp1mwqKmTJvI+NP6U5WQTF3\nTV3K8uxdwdP7R3bhquGdiYoyygOOMx6dTkZe8YHnDuzYnCuHdeTSIR2JrnCFxl179/HyNxlcPrSj\n3jgVaWCqexKTyr2W7R/F0r55Y3ILS2iVEMdd5/Tm/IHtDipsgO2FJcxYnUv2jj2c2TeVPm2b+pRa\nRMKVzlANA4GA47MVWxnQoRk5u0oY3rUlT4wbXOmImOTEeH4ypEMdpxSRSKRyr0VLNu1g264S7jqn\nNxcOav+DPXURkdpS5btwZvaimeWY2bJKpl9lZkvN7Hszm21mA72PWT99tmIbMVHGGb1TVewiUqeq\ns+c+CZgATK5k+gZglHOuwMzGABOB4d7EC3/OOZ6buZ7E+BiGd23Jnn3l9GidRFkgwPtLsjmxW6tj\nvhKjiMixqrLcnXMzzazLEabPrvDlHKBBHTR+c34WD3686qDH2jdvTHJiHFt37uXvl/T3KZmINGRe\nH3O/Cfi4solmNh4YD9CpUyePV133svKL+csHKzipeyvuPq8vK7fsIjrKeOqrtXy/eSdPXjGYU3qk\n+B1TRBo3v0RgAAAJcElEQVQgz8rdzH5EsNxPrmwe59xEgodtSEtL82cMpkey8ou56vm5RJnx8KUD\n6NCiyYGhi2OOb0tuYQntmzf2OaWINFSelLuZDQCeB8Y45/K8WGa4yt6xh2emr+P9pdk4B5NvGkaH\nFk0OmicuJkrFLiK+qnG5m1kn4G3gGudces0jha995QHGv7KANdsKOaNPa351Zk96pib5HUtE5Aeq\nLHczmwKcBiSb2SbgXiAWwDn3LHAP0Ar4V+hGDmXVOXuqPnp2+jqWbd7FM1edwJj+bf2OIyJSqeqM\nlrmiiuk3Azd7lihM5e4u4cmv1nDegLYqdhEJe7qUYDV9sDSbfeWOX5zxw+uti4iEG5V7Nb3z3Wb6\ntWuqY+wiUi+o3KthXW4hSzbt5OLB7f2OIiJSLbpw2BFk5hXxs9e/Y11uIVEG5w9s53ckEZFqUblX\nIiu/mCsmzmHPvnLGpnWkf/tmpOrGGCJST6jcD6O4tIybXp5PUWk5r98ynH7tmvkdSUTkqKjcK1iX\nW8i0VTnMWZ/HmpxCJt84TMUuIvWSyj3EOcev31zM0k07AfjtOb100S8RqbdU7iGz1+WxdNNO7ju/\nLxcNbk/zJoe/FZ6ISH2gcg95dsY6UpLiGTesE41io/2OIyJSIxrnDszPyGfWmu3cOLKril1EIkKD\nL/fygOOed5fTrlkjrj+pi99xREQ80WAPy2zbtZcbXppPwDlWbd3N01eeQOM47bWLSGRosHvuz0xf\nR/q23STEx3DpkA6c27+N35FERDzTIPfcc3btZcq8jVxyQnsevnSg33FERDzX4PbcnXM89MlqygKO\nn/1Il+8VkcjUoMrdOcefP1jB1EWbuG1UNzq1alL1k0RE6qEGVe4vfL2Bl77J4MaRXfm/s3r5HUdE\npNY0iGPuzjk+Xb6Nv3+8inP6teHu8/oQut+riEhEishyLy0L8N6SbJIT41iXW8SUeRtZm1NIz9RE\nHhk7UMUuIhEvIsv98S/S+df0dQe+HtypOQ9fOoDzB7TTWHYRaRAirtyXZO3g2RnruHhwe8YN7UiL\nhDjd91REGpyIK/e/friClKR47rugH80ax/odR0TEFxE1WmbLzj3MzyjgmhM7q9hFpEGLqHL/ZNlW\nAMb0b+tzEhERf0VUuX/8/VZ6pSbRPSXR7ygiIr6KmHLP2bWX+Zn5jNEFwEREIqfcn5u5HoDzB7bz\nOYmIiP8iotw3bC9i8rcZXJ7WUYdkRESIkHJ/8OOVxEVH8ZuzevodRUQkLNT7cl+evZNPl2/jllO7\n0Tqpkd9xRETCQr0v96e+XEtSfAw3jOzqdxQRkbBRL89Q3VNaztRFm5i7IZ9Plm/lF6cfp5OWREQq\nqLLczexF4Dwgxzl3/GGmG/AEcC5QDFzvnFvkddD9vlq1jf/7z1Lyi0pp37wx5w9sx02ndKut1YmI\n1EvV2XOfBEwAJlcyfQzQI/QxHHgm9G+t6NIqgUEdm3P7ad0Z2qVlba1GRKReq7LcnXMzzazLEWa5\nEJjsnHPAHDNrbmZtnXNbPMp4kG4pibx4/dDaWLSISMTw4g3V9kBWha83hR77ATMbb2YLzGxBbm6u\nB6sWEZHDqdPRMs65ic65NOdcWkpKSl2uWkSkQfGi3DcDHSt83SH0mIiI+MSLcn8PuNaCTgR21tbx\ndhERqZ7qDIWcApwGJJvZJuBeIBbAOfcs8BHBYZBrCQ6FvKG2woqISPVUZ7TMFVVMd8AdniUSEZEa\nq/eXHxARkR9SuYuIRCALHlXxYcVmuUBmNWfvBGz0YLXNgJ0eLCfc8kD4ZVKeqoVbJuWpWjhk6uyc\nq3osuXMu7D+AXI+WMzES84RjJuWpf5mUp35mquyjvhyW2eHRct73aDnhlgfCL5PyVC3cMilP1cIx\n02HVl3L35E8q55xXL2i45YHwy6Q8VQu3TMpTtXDMdFj1pdwn+h3gEOGWB8Ivk/JULdwyKU/VwjHT\nYfn2hqqIiNSe+rLnLiIiR0HlLiISgXwpdzPraGbTzGyFmS03s1+GHm9pZp+b2ZrQvy0qPOf3ZrbW\nzFab2dkVHn/AzLLMrDBM8nxiZktCy3nWzKLDINP00GOLQx+t/cpjZkkVciw2s+1m9rjPr8/lZrY0\ntJyHjjbLsWYys1ah+QvNbMIhy6rz7bqKPDXerj3OU+Nt2stMXm3XnqrtsZaVjPFsC5wQ+jwJSAf6\nAg8Dvws9/jvgodDnfYElQDzQFVgHRIemnRhaXmGY5Gka+teAqcC4MMg0HUgLl5/ZIctdCJzqVx6g\nFcGTUlJC870MnFFHr1ECcDJwGzDhkGX5sV0fKU+Nt2uP89R4m/Y6kxfbtZcfvq34kBfiXWA0sBpo\nW+FFXx36/PfA7yvM/ykw4pBlHPMvQS3liSU4lvVyvzN59YtQC69RT4J38TK/8gBDgS8rPH4N8K+6\neI0qzHd9ZUVRl9t1NfN4tl3XJE9tbNMevkaebdc1+fD9mLsF7886GJgLpLr//1rwW4HU0OfVvpVf\nOOQxs0+BHGA38N9wyAS8HPpz8W4zszDIAzAOeNOFfiN8yrMW6GVmXcwsBriIg28+U5uZ6owXebzc\nrj16fTzbpj3MBB5t1zXla7mbWSLBP/F+5ZzbVXFa6IWp0xfHqzzOubMJ/m8fD5weBpmucs71A04J\nfVzjc579xgFTjjWLF3mccwXA7cCbwCwgAyj3M5PXwm27Drdt2sNM+9V4u/aCb+VuZrEEX8zXnHNv\nhx7eZmZtQ9PbEtxLgDq4lZ/XeZxzewn+iXeh35mcc/v/3Q28DgzzM09o3oFAjHNu4bFk8TKPc+59\n59xw59wIgn+Op9dRplrndZ6abtde5fFqm/YyU2jeGm/XXvFrtIwBLwArnXP/rDDpPeC60OfXEdyI\n9j8+zszizawr0AOYF255zCyxwgYRA/wYWOVzphgzSw4tMxY4D1jmV54Kz7uCGuzdeJln/0iL0IiI\nnwLP11GmWuVVHq+2aw/zeLJNe5mpghpt157y40A/wXebHbAUWBz6OJfgyIUvgTXAF0DLCs/5I8ER\nDquBMRUef5jg8dNA6N/7/MpD8Ljc/NBylgFPEfxf3LfXiOC7+wtDy1kOPMFhRq3U5c8sNG090DtM\ntqEpwIrQxzGNbqpBpgwgHygMbb99fd6uf5DHq+3awzyebNNe/8y82K69/NDlB0REIpDvo2VERMR7\nKncRkQikchcRiUAqdxGRCKRyFxGJQCp3EZEIpHIXEYlA/w8+S2M5OI8HxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1119c7438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "leverage = 0.05/(ret_day.ewm(60).std()*np.sqrt(250))\n",
    "leverage_mon = leverage.resample('M').ffill()\n",
    "\n",
    "positions = ret_mon_slice[ret_mon_slice.columns[-6:]]\n",
    "returns = ret_mon_slice[ret_mon_slice.columns[:6]]\n",
    "positions.columns = ['ES', 'FESX', 'GC', 'NK', 'TU', 'ED']\n",
    "\n",
    "position_returns = returns * positions.shift(1)\n",
    "vol_adj_rets = position_returns * leverage_mon.shift(1)\n",
    "total_rets = vol_adj_rets.mean(1).dropna()\n",
    "(total_rets + 1).cumprod().plot(title='vola-adjusteering')\n",
    "m = total_rets.mean() * 12\n",
    "s = total_rets.std() * np.sqrt(12)\n",
    "print ('Sharpe', m/s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
