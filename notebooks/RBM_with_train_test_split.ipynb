{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid , save_image\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    used_data = pd.read_csv('../data/data.csv', index_col=0, parse_dates=True)\n",
    "    return used_data\n",
    "\n",
    "def get_all_tickers():\n",
    "    used_data = get_data()\n",
    "    return used_data.columns\n",
    "\n",
    "def get_returns():\n",
    "    used_data = get_data()\n",
    "    ret_day = ret_day = used_data.fillna(0)\n",
    "    S = np.exp(used_data.fillna(0)).cumprod()\n",
    "    ret_mon = S.resample('M').ffill().pct_change().dropna() # start 2000-02-29\n",
    "    return ret_day, ret_mon\n",
    "    \n",
    "def form_labels(tic):\n",
    "    ret_day, ret_mon = get_returns()\n",
    "    median_ret = ret_mon.median(1)\n",
    "    labels = ret_mon.shift(-1).gt(median_ret.shift(-1), axis=0).astype(int)[tic]\n",
    "    labels.name = 'label'\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_features(tic):\n",
    "    ret_day, ret_mon = get_returns()\n",
    "    \n",
    "    feature_data = []\n",
    "        \n",
    "    daily = ret_day[tic]\n",
    "    dfs = []\n",
    "    idx = range(13, len(ret_mon) - 1)\n",
    "    for t in idx:\n",
    "        current_y = ret_mon.index[t].year\n",
    "        current_mon = ret_mon.index[t].month\n",
    "        next_mon_isjan = (ret_mon.index[t+1].month == 1)\n",
    "\n",
    "        start = t - 13\n",
    "        end = t - 2\n",
    "\n",
    "        ret_mon_slice = ret_mon[tic].iloc[start:end+1]\n",
    "\n",
    "        last_date = (daily[(daily.index.year == current_y) \n",
    "                           & (daily.index.month == current_mon)].last_valid_index())\n",
    "\n",
    "        last_date_loc = daily.index.get_loc(last_date)\n",
    "        start_date_loc = last_date_loc - 19\n",
    "\n",
    "        daily_rets_slice = daily.iloc[start_date_loc:last_date_loc + 1]\n",
    "\n",
    "        daily_rets_slice.index = ['R_d_' + str(i) for i in range(1, 21)]\n",
    "        ret_mon_slice.index = ['R_m_' + str(i) for i in range(1, 13)]\n",
    "\n",
    "        conc = pd.concat([daily_rets_slice, ret_mon_slice])\n",
    "        conc['JAN'] = next_mon_isjan\n",
    "\n",
    "        conc = conc.to_frame()\n",
    "        conc.columns = [t]\n",
    "        dfs.append(conc)\n",
    "    feats_t = pd.concat(dfs, axis=1).T\n",
    "    feature_data.append(feats_t)\n",
    "    \n",
    "    date_idx = ret_mon.index[idx]\n",
    "    feature_data_df = pd.concat(feature_data, axis=0).set_index(date_idx)\n",
    "    return feature_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_feats_labels(tickers):\n",
    "    full_data_by_tic = []\n",
    "    for tic in tickers:\n",
    "        feats = form_features(tic)\n",
    "        labels = form_labels(tic)\n",
    "        conc = pd.concat([feats, labels], axis=1, join='inner')\n",
    "        full_data_by_tic.append(conc)\n",
    "    return pd.concat(full_data_by_tic, axis=0) # datetime index not unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = 0.7\n",
    "def split_test_train(train_set_size=train_size):\n",
    "    tickers = get_all_tickers()\n",
    "    Xtrains = []\n",
    "    ytrains = []\n",
    "    Xtests = []\n",
    "    ytests = []\n",
    "    for tic in tickers:\n",
    "        data = form_feats_labels([tic])\n",
    "        X = data[data.columns[:-1]].as_matrix()\n",
    "        y = data.label.as_matrix()\n",
    "        N = len(y)\n",
    "        train_set_stop = int(N * train_set_size)\n",
    "        \n",
    "        Xtrain = X[0:train_set_stop]\n",
    "        Xtrains.append(Xtrain)\n",
    "        ytrain = y[0: train_set_stop]\n",
    "        ytrains.append(ytrain)\n",
    "        \n",
    "        Xtest = X[train_set_stop:]\n",
    "        Xtests.append(Xtest)\n",
    "        ytest = y[train_set_stop:]\n",
    "        ytests.append(ytest)\n",
    "    \n",
    "    Xtrains_c = np.concatenate(Xtrains)\n",
    "    ytrains_c = np.concatenate(ytrains)\n",
    "    Xtests_c = np.concatenate(Xtests)\n",
    "    ytests_c = np.concatenate(ytests)\n",
    "    return Xtrains_c, ytrains_c, Xtests_c, ytests_c      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FutureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(33, 50)\n",
    "        self.fc21 = nn.Linear(50, 4)\n",
    "        self.fc22 = nn.Linear(50, 4)\n",
    "        self.fc3 = nn.Linear(4, 50)\n",
    "        self.fc4 = nn.Linear(50, 33)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = Variable(torch.rand(std.size()), requires_grad=False)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 33))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "        \n",
    "    def loss_function(self, recon_x, x, mu, logvar):\n",
    "        MSE = F.mse_loss(recon_x, x.view(-1, 33), size_average=False)\n",
    "\n",
    "        # see Appendix B from VAE paper:\n",
    "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "        # https://arxiv.org/abs/1312.6114\n",
    "        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        return MSE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train and test data\n",
    "Xtrain, ytrain, Xtest, ytest = split_test_train()\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = FutureDataset(Xtrain, ytrain)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = FutureDataset(Xtest, ytest)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_interval = 100\n",
    "number_of_epochs = 500\n",
    "\n",
    "vae = VAE()\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae.train()\n",
    "for epoch in range(number_of_epochs):\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data.float())\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = vae(data)\n",
    "        loss = vae.loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % log_interval == 0:\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "test_loss = 0\n",
    "for i, (data, _) in enumerate(test_loader):\n",
    "    data = Variable(data.float(), requires_grad=False)\n",
    "    recon_batch, mu, logvar = vae(data)\n",
    "    test_loss += vae.loss_function(recon_batch, data, mu, logvar).data[0]\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build encoded dataset\n",
    "Xenc = np.array([]).reshape(0, 4)\n",
    "yenc = np.array([])\n",
    "for _, (data,target) in enumerate(train_loader):\n",
    "    data = Variable(data.view(-1,33)).float()\n",
    "    labels = Variable(target).type(torch.LongTensor)\n",
    "    \n",
    "    _, data, _ = vae(data)\n",
    "    \n",
    "    batch = data.cpu().data.numpy()\n",
    "    Xenc = np.vstack((Xenc, batch))\n",
    "    yenc = np.append(yenc, target.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RANDOM FOREST CLASSIFIER\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(Xenc, yenc)\n",
    "score = cross_val_score(clf, Xenc, yenc)\n",
    "print(score.mean())\n",
    "\n",
    "print(\"What features are prefered\", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NAIVE BAYESIAN CLASSIFIER\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(Xenc, yenc)\n",
    "score = cross_val_score(gnb, Xenc, yenc)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ORGINAL DATA\n",
    "tickers = get_all_tickers()\n",
    "X_and_y = form_feats_labels(tickers)\n",
    "Xorg = X_and_y[X_and_y.columns[:-1]].as_matrix()\n",
    "yorg = X_and_y.label.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLP ONLY\n",
    "mlp = MLPClassifier(activation='logistic',\n",
    "                    batch_size=32,\n",
    "                    hidden_layer_sizes=[5, 5],\n",
    "                    alpha=0.1)\n",
    "mlp.fit(Xtrain, ytrain)\n",
    "score = cross_val_score(clf, Xtest, ytest)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RANDOM FOREST CLASSIFIER ONLY\n",
    "clf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "score = cross_val_score(clf, Xtest, ytest)\n",
    "print(score.mean())\n",
    "\n",
    "print(\"What features are prefered: \\n\", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ADABOOST ONLY\n",
    "ada = AdaBoostClassifier(n_estimators=10)\n",
    "ada.fit(Xorg, yorg)  \n",
    "score = cross_val_score(ada, Xorg, yorg)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVC ONLY\n",
    "svc = SVC(gamma=2, C=1)\n",
    "svc.fit(Xorg, yorg)\n",
    "score = cross_val_score(svc, Xorg, yorg)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BROKEN, PREDICTION RESULTS FROM ENCODER PIPELINE\n",
    "prediction_outputs = []\n",
    "returns = []\n",
    "\n",
    "classifier = clf\n",
    "\n",
    "for idx, observation in enumerate(Xorg):\n",
    "    data = torch.from_numpy(observation)\n",
    "\n",
    "    data = Variable(data).float()\n",
    "    _, data, _ = vae(data)\n",
    "    output = classifier.predict_proba(data.cpu().data.numpy())\n",
    "    prediction_outputs.append(output[0])\n",
    "\n",
    "len(prediction_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_positions(prediction_outputs):\n",
    "    result_df = pd.DataFrame(prediction_outputs, columns=[\"loser_p\", \"winner_p\"])\n",
    "    label = (result_df[\"winner_p\"] > result_df[\"loser_p\"]).astype(int) # <\n",
    "    result_df[\"longshort\"] = label.map({1: 1, 0: -1})\n",
    "\n",
    "    print(\"Predicted long count:\", sum(label))\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dfs = {}\n",
    "\n",
    "for tic in [\"ES\", \"FESX\", \"GC\", \"NK\", \"TU\", \"ED\"]:\n",
    "    test_start = int(len(X) * train_size) + 1\n",
    "    X = form_features(tic).iloc[test_start:]\n",
    "    prediction_outputs = clf.predict_proba(X)\n",
    "    df = get_positions(prediction_outputs).set_index(X.index)\n",
    "    result_dfs[tic] = df[['longshort']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret_day, ret_mon = get_returns()\n",
    "ret_mon_slice = ret_mon.iloc[13:]\n",
    "for key in result_dfs.keys():\n",
    "    newcol = str(key) + '_pos'\n",
    "    ret_mon_slice[newcol] = result_dfs[key]\n",
    "ret_mon_slice = ret_mon_slice.resample('M').ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leverage = 0.05/(ret_day.ewm(60).std()*np.sqrt(250))\n",
    "leverage_mon = leverage.resample('M').ffill()\n",
    "\n",
    "positions = ret_mon_slice[ret_mon_slice.columns[-6:]]\n",
    "returns = ret_mon_slice[ret_mon_slice.columns[:6]]\n",
    "positions.columns = ['ES', 'FESX', 'GC', 'NK', 'TU', 'ED']\n",
    "\n",
    "position_returns = returns * positions.shift(1)\n",
    "vol_adj_rets = (position_returns * leverage_mon.shift(1)).dropna()\n",
    "total_rets = vol_adj_rets.mean(1)\n",
    "(total_rets + 1).cumprod().plot(title='vola-adjusteering')\n",
    "m = total_rets.mean() * 12\n",
    "s = total_rets.std() * np.sqrt(12)\n",
    "print ('Sharpe', m/s)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
